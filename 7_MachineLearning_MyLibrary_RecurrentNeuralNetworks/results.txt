W2:
[[ 0.30825529  0.0433293  -0.45610915  0.0701741  -0.23929169 -0.09141518 -0.2099097   0.0777077  -0.11440234  0.14096912  0.0871431  -0.04383051  0.01470824  0.16749717 -0.06794168  0.16716837 -0.0035266   0.04918502  0.14592075  0.24310347  0.09508686  0.0106572   0.13157865 -0.28215884  0.29923208 -0.24200049  0.16499401 -0.10300177  0.09261105 -0.0212822 ]]
Training accuracy is: 0.47755
W2:
[[ 0.126996   -0.02272694  0.01548499 -0.25974209  0.07312527  0.12685961  0.20160216  0.41974191  0.09628806 -0.26626745  0.05058257 -0.12730306 -0.16373847 -0.15915026  0.012717   -0.18413995  0.06856586 -0.41006663 -0.64672462 -0.0354621 ]]
step: 0, loss: 0.763226069741
step: 100, loss: 0.240651777023
step: 200, loss: 0.185924592297
step: 300, loss: 0.169100472726
step: 400, loss: 0.162061562297
step: 500, loss: 0.158121659805
step: 600, loss: 0.155482769966
step: 700, loss: 0.15348466228
step: 800, loss: 0.151768421633
step: 900, loss: 0.150131390186
step: 1000, loss: 0.14846815162
step: 1100, loss: 0.146759867762
step: 1200, loss: 0.145055268118
step: 1300, loss: 0.143417434696
step: 1400, loss: 0.141882137822
step: 1500, loss: 0.140452899514
step: 1600, loss: 0.139113560728
step: 1700, loss: 0.137840804272
step: 1800, loss: 0.136612011136
step: 1900, loss: 0.135409413954
step: 2000, loss: 0.134222068723
step: 2100, loss: 0.133046231295
step: 2200, loss: 0.131884196157
step: 2300, loss: 0.130741981263
step: 2400, loss: 0.129626787184
step: 2500, loss: 0.128545088341
step: 2600, loss: 0.127501614162
step: 2700, loss: 0.126499037124
step: 2800, loss: 0.125538103275
step: 2900, loss: 0.124617996899
step: 3000, loss: 0.123736796779
Training accuracy is: 0.947425
Test accuracy is: 0.9434
W2:
[[ 0.43670724  0.01936328  0.92416103 -0.04849482 -0.15614494  1.56209045  0.20921152  1.33666977 -0.10129999 -2.39465496  1.29811858  0.19715767 -0.19628421  0.51953923 -0.14198351 -0.24659902  0.84021722 -0.8348329  -2.56635302 -0.25984838]]
